<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>306c83da6a154d53a9a3ffa6c8d918fa</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="machine-learning---nonparametric-models" class="cell markdown" id="6LlLryJhGSSe">
<h1>Machine Learning - Nonparametric Models</h1>
<h2 id="masaccio-braun">Masaccio Braun</h2>
<p>Linear models are a useful means of showing the relationship between two quantities, but oftentimes a linear model is not sufficient to make novel and accurate predictions. As such, we want to discover trends without assuming linearity. But how are we to transition from a straight line to a smooth curve? The answer is that a smooth curve can be interpreted as collection of many small lines.</p>
<h3 id="locally-weighted-regression---loess">Locally Weighted Regression - Loess</h3>
<p>One way of interpreting this collection of many small lines is through loess, which is form of nonparametric regression. Although there are local parametric assumptions, such that local predictions can be linear but global predictions are nonlinear.</p>
</section>
<div class="cell markdown" id="7fiCWeoHGThY">
<h3 id="linear-regression">Linear Regression</h3>
<p>The main idea of linear regression is the assumption that:</p>
<p><span class="math display">$$\large y = X\cdot\beta +\sigma\epsilon $$</span></p>
<p>...where <span class="math inline"><em>y</em></span> is our target dependent variable and <span class="math inline"><em>X</em></span> is our predictive independent variable(s).</p>
<p>If we pre-multiply this equation with a matrix of weights we get:</p>
<p><span class="math display">$$\large W_i y = W_i X\cdot\beta +\sigma W_i \epsilon $$</span></p>
<p>The independent observations are the rows of the matrix <span class="math inline"><em>X</em></span>. Each row has a number of columns (this is the number of features) and we can denote it by <span class="math inline"><em>p</em></span>. The distance between two data points or independent observations is the Euclidean distance between the two represented <span class="math inline"><em>p</em>−</span>dimensional vectors. The Euclidean distance is also known as the <span class="math inline"><em>L</em><sup>2</sup></span> norm. The equation is:</p>
<p><span class="math display">$$dist(\vec{v},\vec{w})=\sqrt{(v_1-w_1)^2+(v_2-w_2)^2+...+(v_p-w_p)^2}$$</span></p>
<p>We shall have <span class="math inline"><em>n</em></span> different weight vectors because we have <span class="math inline"><em>n</em></span> different observations.</p>
<p>All in all, linear regression can be seen as a linear combination of the observed outputs (values of the dependent variable) and the predictions we make are linear combinations of the actual observed values of the dependent variables.</p>
<h3 id="comparision-with-loess">Comparision with loess</h3>
<p>So for loess, <span class="math inline"><em>ŷ</em></span> (our prediction) is obtained as a different linear combination of the values of <span class="math inline"><em>y</em></span>. The loess model does not learn a fixed set of parameters (<span class="math inline"><em>β</em></span>) like linear regression does. Instead, parameters are determined for each individual <span class="math inline"><em>x</em></span>. While <span class="math inline"><em>β</em></span> is calculated, larger weights are given to the points in the training set lying closer to <span class="math inline"><em>x</em></span> than to the points lying farther away from <span class="math inline"><em>x</em></span>.</p>
<h3 id="random-forest-regression">Random Forest Regression</h3>
<p>The random forest regression is an ensemble bagging algorithm that combines and averages the outputs of multiple decision trees. It is a desirable method because it tends to have a reduced risk of overfitting and is more suited for determining the relative importances of features; however, on noisier data it has a higher risk of overfitting. This is also a nonparametric model and though it is popular machine learning method, loess seems to be a strong competitor.</p>
</div>
<div class="cell markdown" id="JjJzHBR-oVNF">
<p>To compare the effectiveness of each nonlinear model, I will be performing a univariate analysis using each model on the Boston Housing Prices.csv dataset, which lists the median house prices (categorical dependent variable) of many homes in the Boston area, along with 16 predictor attributes (4 categorical and 12 numerical independent variables). I will be performing a univariate analysis of the 'rooms' predictor (number of rooms) on the 'cmedv' target.</p>
</div>
<div class="cell code" id="bns5jPn7JYbr">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import libraries and models</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> linalg</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.interpolate <span class="im">import</span> interp1d</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error <span class="im">as</span> mse</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span></code></pre></div>
</div>
<div class="cell code" id="uvJcOKMAJj06">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># High-resolution images</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">&#39;retina&#39;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">&#39;figure.dpi&#39;</span>] <span class="op">=</span> <span class="dv">120</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="u3GWUujIJj7q" data-outputId="f2a72f47-769c-49af-ae93-11e909a8b30c">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mount Google Drive</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">&#39;/content/drive&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mounted at /content/drive
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:270,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="olrWr0sdK938" data-outputId="92dbb97e-c82f-4889-d09a-4d5ba6341c0c">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&#39;drive/MyDrive/Data/Boston Housing Prices.csv&#39;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>data.head(<span class="dv">5</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">

  <div id="df-18782c43-73fe-44e2-9fda-675572774030">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>town</th>
      <th>tract</th>
      <th>longitude</th>
      <th>latitude</th>
      <th>crime</th>
      <th>residential</th>
      <th>industrial</th>
      <th>river</th>
      <th>nox</th>
      <th>rooms</th>
      <th>older</th>
      <th>distance</th>
      <th>highway</th>
      <th>tax</th>
      <th>ptratio</th>
      <th>lstat</th>
      <th>cmedv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Nahant</td>
      <td>2011</td>
      <td>-70.955002</td>
      <td>42.255001</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>no</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.199997</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296</td>
      <td>15.300000</td>
      <td>4.98</td>
      <td>24.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Swampscott</td>
      <td>2021</td>
      <td>-70.949997</td>
      <td>42.287498</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>no</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.900002</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.799999</td>
      <td>9.14</td>
      <td>21.600000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Swampscott</td>
      <td>2022</td>
      <td>-70.935997</td>
      <td>42.283001</td>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>no</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.099998</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.799999</td>
      <td>4.03</td>
      <td>34.700001</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Marblehead</td>
      <td>2031</td>
      <td>-70.928001</td>
      <td>42.292999</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>no</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.799999</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.700001</td>
      <td>2.94</td>
      <td>33.400002</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Marblehead</td>
      <td>2032</td>
      <td>-70.921997</td>
      <td>42.298000</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>no</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.200001</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.700001</td>
      <td>5.33</td>
      <td>36.200001</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-18782c43-73fe-44e2-9fda-675572774030')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-18782c43-73fe-44e2-9fda-675572774030 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-18782c43-73fe-44e2-9fda-675572774030');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:848,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="G5yYLOaoK9-H" data-outputId="521f217d-94bb-4e7b-ffad-6a5573fae12a">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select variables and plot data</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[<span class="st">&#39;rooms&#39;</span>].values</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;cmedv&#39;</span>].values</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Data plot</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">8</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">3</span>, <span class="dv">9</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="dv">51</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>ax.scatter(x<span class="op">=</span>x, y<span class="op">=</span>y,s<span class="op">=</span><span class="dv">25</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&#39;Number of Rooms&#39;</span>,fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&#39;House Price (Thousands of Dollars)&#39;</span>,fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">&#39;Boston Housing Prices&#39;</span>,fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>ax.grid(b<span class="op">=</span><span class="va">True</span>,which<span class="op">=</span><span class="st">&#39;major&#39;</span>, color <span class="op">=</span><span class="st">&#39;grey&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;-&#39;</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>ax.grid(b<span class="op">=</span><span class="va">True</span>,which<span class="op">=</span><span class="st">&#39;minor&#39;</span>, color <span class="op">=</span><span class="st">&#39;grey&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>ax.minorticks_on()</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;RoomVsCMedV.png&#39;</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>files.download(<span class="st">&#39;RoomVsCMedV.png&#39;</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre>
</div>
<div class="output display_data">
<pre><code>&lt;IPython.core.display.Javascript object&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_5d7290777be142f58f8e217fea7bd054/897c6d9f98a7d44f9c52e5714af2b5ec8efd9aeb.png" width="1018" height="831" /></p>
</div>
</div>
<div class="cell markdown" id="rEE5097Ec7O5">
<p>As we can see from the scatterplot, though in an overall sense, as the number of rooms increases the median house price tends to increase, the data is decidedly nonlinear. Because of this, it will likely be the case that our linear model will make relatively inaccurate predictions.</p>
</div>
<div class="cell code" id="tzNINy57KNJh">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define data standardization and cross-validation methods</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> StandardScaler()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span>k, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">410</span>)</span></code></pre></div>
</div>
<div class="cell code" id="RxGHIr6NKNPX">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define imported model execution function</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> DoKFold(model, x , y, scaler<span class="op">=</span>ss, split<span class="op">=</span>kf):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  pred_mse <span class="op">=</span> []</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idxTrain, idxTest <span class="kw">in</span> kf.split(x, y):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> ss.fit_transform(x[idxTrain].reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> ss.transform(x[idxTest].reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    ytrain <span class="op">=</span> y[idxTrain]</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    ytest <span class="op">=</span> y[idxTest]</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    model.fit(xtrain, ytrain)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    ypred <span class="op">=</span> model.predict(xtest)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    pred_mse.append(mse(ytest, ypred))</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  A <span class="op">=</span> np.column_stack([xtest,ypred])</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  A <span class="op">=</span> A[np.argsort(A[:,<span class="dv">0</span>])]</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> A, xtest, ytest, pred_mse</span></code></pre></div>
</div>
<div class="cell code" id="_5hsyq4WW5pU">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>ols <span class="op">=</span> LinearRegression()</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:475,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="DscSdOTTYGTO" data-outputId="6425cbb3-f5e7-48f6-b5ef-725ca73ff2dd">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordinary Least Squares</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>L, xtest_ols, ytest_ols, mse_ols <span class="op">=</span> DoKFold(ols, x, y)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Model plot</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest_ols, ytest_ols, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, alpha<span class="op">=</span><span class="fl">.5</span>, edgecolors<span class="op">=</span><span class="st">&#39;k&#39;</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.plot(L[:,<span class="dv">0</span>], L[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;Ordinary Least Squares&#39;</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Linear Model&#39;</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The MSE for the Ordinary Least Squares Linear Regression is: &#39;</span> <span class="op">+</span> <span class="bu">str</span>(np.mean(mse_ols)))</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_5d7290777be142f58f8e217fea7bd054/17e01b41a295c12b5d1a30fb3f18de079101befe.png" width="614" height="440" /></p>
</div>
<div class="output stream stdout">
<pre><code>The MSE for the Ordinary Least Squares Linear Regression is: 44.28641009426175
</code></pre>
</div>
</div>
<div class="cell markdown" id="jm5k7u3rdWtq">
<p>Certainly the linear model reflects an overall trend, but we want to create a model that is capable of predicting a greater portion of the median house prices based on the number of rooms with greater specificity, such that it is better fit to the data on which we will train it.</p>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:492,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="VnZL6WoNYK6E" data-outputId="79787906-8993-413a-a566-5c603a810f6c">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Regression</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>num_est <span class="op">=</span> np.arange(<span class="dv">30</span>, <span class="dv">51</span>, <span class="dv">1</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>max_depth <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>min_split <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>te_num_est <span class="op">=</span> []</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>mse_rfr <span class="op">=</span> []</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> num_est:</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  rfr <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span>n, max_depth<span class="op">=</span>max_depth, </span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>                              min_samples_split<span class="op">=</span>min_split)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  F, xtest_rfr, ytest_rfr, yhat_mse_rfr <span class="op">=</span> DoKFold(rfr, x, y, <span class="st">&#39;Random Forest&#39;</span>, <span class="st">&#39;Ensemble&#39;</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  mse_rfr.append(np.mean(yhat_mse_rfr))</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  te_num_est.append(n)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>idx_min_rfr <span class="op">=</span> np.argmin(mse_rfr)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Model plot</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest_rfr, ytest_rfr, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, alpha<span class="op">=</span><span class="fl">.5</span>, edgecolors<span class="op">=</span><span class="st">&#39;k&#39;</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>plt.plot(F[:,<span class="dv">0</span>], F[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;Random Forest&#39;</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Ensemble Model&#39;</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Optimal number of estimator trees in range tested: &#39;</span>, te_num_est[idx_min_rfr])  </span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The MSE for the Random Forest Regression is: &#39;</span>, mse_rfr[idx_min_rfr])</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_5d7290777be142f58f8e217fea7bd054/5cdd4ede4688647935aed9ee29835156133fb2cd.png" width="614" height="440" /></p>
</div>
<div class="output stream stdout">
<pre><code>Optimal number of estimator trees in range tested:  45
The MSE for the Random Forest Regression is:  35.51087903147884
</code></pre>
</div>
</div>
<div class="cell markdown" id="o95L334DduQX">
<p>The ensemble model certainly predicts the the trend of the relationship between the number of rooms and median house price with greater precision. But since the data, though nonlinear, has undertones of linearity, I suspect loess will be a better model.</p>
</div>
<div class="cell markdown" id="4UFxxaBDeYpR">
<p>Perhaps the most important aspect of loess is the weights. I will test 3 different kernelling methods for loess: tricubic, Epanechnikov, and quartic. Each kernel has a specific bandwith with which a given neigborhood of data points will be interpolated.</p>
</div>
<div class="cell code" id="ucrC__W2KM7a">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define kernels</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Tricubic Kernel</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Tricubic(x):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(x.shape) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  d <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.where(d<span class="op">&gt;</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">70</span><span class="op">/</span><span class="dv">81</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>d<span class="op">**</span><span class="dv">3</span>)<span class="op">**</span><span class="dv">3</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Epanechnikov Kernel</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Epanechnikov(x):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.where(np.<span class="bu">abs</span>(x)<span class="op">&gt;</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">3</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>np.<span class="bu">abs</span>(x)<span class="op">**</span><span class="dv">2</span>)) </span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Quartic Kernel</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Quartic(x):</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.where(np.<span class="bu">abs</span>(x)<span class="op">&gt;</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">15</span><span class="op">/</span><span class="dv">16</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>np.<span class="bu">abs</span>(x)<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>) </span></code></pre></div>
</div>
<div class="cell markdown" id="S6YHeeztenzP">
<p>This animation is from the scikit-lego documentation.</p>
<figure>
<center>
<img src='https://drive.google.com/uc?id=1bQmo-j35etyEWt7Ce8TSo01YSOhZQBeY'width='800px'/>
<figcaption>Example of how weights work</figcaption></center>
</figure>
<p>As the model runs, groupings of data points are weighted according to the progression of the weight function at the given time.</p>
</div>
<div class="cell code" id="zuPzMGxlK9kd">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Smoother model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lwr(x, y, xnew, kern, tau):</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    yest <span class="op">=</span> np.zeros(n)   </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> np.array([kern((x <span class="op">-</span> x[i])<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>tau)) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)])     </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        weights <span class="op">=</span> w[:, i]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> np.array([np.<span class="bu">sum</span>(weights <span class="op">*</span> y), np.<span class="bu">sum</span>(weights <span class="op">*</span> y <span class="op">*</span> x)])</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        A <span class="op">=</span> np.array([[np.<span class="bu">sum</span>(weights), np.<span class="bu">sum</span>(weights <span class="op">*</span> x)], [np.<span class="bu">sum</span>(weights <span class="op">*</span> x), np.<span class="bu">sum</span>(weights <span class="op">*</span> x <span class="op">*</span> x)]])</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        beta, res, rnk, s <span class="op">=</span> linalg.lstsq(A, b)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        yest[i] <span class="op">=</span> beta[<span class="dv">0</span>] <span class="op">+</span> beta[<span class="dv">1</span>] <span class="op">*</span> x[i]</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> interp1d(x, yest, fill_value<span class="op">=</span><span class="st">&#39;extrapolate&#39;</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> f(xnew)</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:492,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="2MM-g0RMMUDV" data-outputId="2b23e1ac-480a-4911-9809-26e93152018c">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Locally Weighted Regression</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Tricubic</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>tau <span class="op">=</span> np.arange(<span class="fl">.01</span>, <span class="fl">.11</span>, <span class="fl">.01</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>mse_lwr_tri <span class="op">=</span> []</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>te_tau_tri <span class="op">=</span> []</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idxtrain,idxtest <span class="kw">in</span> kf.split(x):</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  ytrain <span class="op">=</span> y[idxtrain]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> x[idxtrain]</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> ss.fit_transform(xtrain.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> xtrain.ravel()</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  ytest <span class="op">=</span> y[idxtest]</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> x[idxtest]</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> ss.transform(xtest.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> xtest.ravel()</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> t <span class="kw">in</span> tau:</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    yhat_lwr_tri <span class="op">=</span> lwr(xtrain,ytrain,xtest,Tricubic,t)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    mse_lwr_tri.append(mse(ytest, yhat_lwr_tri))</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    te_tau_tri.append(t)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>  T <span class="op">=</span> np.column_stack([xtest,yhat_lwr_tri])</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>  T <span class="op">=</span> T[np.argsort(T[:,<span class="dv">0</span>])]</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>idx_min_lwr <span class="op">=</span> np.argmin(mse_lwr_tri)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Model plot </span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest, ytest, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, alpha<span class="op">=</span><span class="fl">.5</span>, edgecolors<span class="op">=</span><span class="st">&#39;k&#39;</span>)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>plt.plot(T[:,<span class="dv">0</span>], T[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;Loess&#39;</span>)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Loess with Tricubic Kernel&#39;</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Optimal Tau in range tested: &#39;</span>, te_tau_tri[idx_min_lwr])</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The MSE for the Locally Weighted Regression is: &#39;</span>, mse_lwr_tri[idx_min_lwr])</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_5d7290777be142f58f8e217fea7bd054/2bab8b51b417cd27daa8fee0767be6ae0cdfcbbd.png" width="614" height="440" /></p>
</div>
<div class="output stream stdout">
<pre><code>Optimal Tau in range tested:  0.09999999999999999
The MSE for the Locally Weighted Regression is:  15.580597196050634
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:492,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ZarY-skm11Lz" data-outputId="1bbdd451-c640-4354-fe82-a481da98695f">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Locally Weighted Regression</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Epanechnikov</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>tau <span class="op">=</span> np.arange(<span class="fl">.01</span>, <span class="fl">.11</span>, <span class="fl">.01</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>mse_lwr_epa <span class="op">=</span> []</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>te_tau_epa <span class="op">=</span> []</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idxtrain,idxtest <span class="kw">in</span> kf.split(x):</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  ytrain <span class="op">=</span> y[idxtrain]</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> x[idxtrain]</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> ss.fit_transform(xtrain.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> xtrain.ravel()</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  ytest <span class="op">=</span> y[idxtest]</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> x[idxtest]</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> ss.transform(xtest.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> xtest.ravel()</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> t <span class="kw">in</span> tau:</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    yhat_lwr_epa <span class="op">=</span> lwr(xtrain,ytrain,xtest,Epanechnikov,t)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    mse_lwr_epa.append(mse(ytest, yhat_lwr_epa))</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    te_tau_epa.append(t)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>  E <span class="op">=</span> np.column_stack([xtest,yhat_lwr_epa])</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>  E <span class="op">=</span> E[np.argsort(E[:,<span class="dv">0</span>])]</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>idx_min_lwr <span class="op">=</span> np.argmin(mse_lwr_epa)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Model plot</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest, ytest, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, alpha<span class="op">=</span><span class="fl">.5</span>, edgecolors<span class="op">=</span><span class="st">&#39;k&#39;</span>)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>plt.plot(E[:,<span class="dv">0</span>], E[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;Loess&#39;</span>)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Loess with Epanechnikov Kernel&#39;</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Optimal Tau in range tested: &#39;</span>, te_tau_epa[idx_min_lwr])</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The MSE for the Locally Weighted Regression is: &#39;</span>, mse_lwr_epa[idx_min_lwr])</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_5d7290777be142f58f8e217fea7bd054/47bbb7ee53b9b0519bc260c3049f03cc7cfbf811.png" width="614" height="440" /></p>
</div>
<div class="output stream stdout">
<pre><code>Optimal Tau in range tested:  0.09
The MSE for the Locally Weighted Regression is:  15.660251150735611
</code></pre>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:492,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="KoM_I-tY11am" data-outputId="b8079997-7dc6-4836-a6d4-39c2bd8e6671">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Locally Weighted Regression</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Quartic</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>tau <span class="op">=</span> np.arange(<span class="fl">.01</span>, <span class="fl">.11</span>, <span class="fl">.01</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>mse_lwr_qua <span class="op">=</span> []</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>te_tau_qua <span class="op">=</span> []</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idxtrain,idxtest <span class="kw">in</span> kf.split(x):</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>  ytrain <span class="op">=</span> y[idxtrain]</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> x[idxtrain]</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> ss.fit_transform(xtrain.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>  xtrain <span class="op">=</span> xtrain.ravel()</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>  ytest <span class="op">=</span> y[idxtest]</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> x[idxtest]</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> ss.transform(xtest.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>  xtest <span class="op">=</span> xtest.ravel()</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> t <span class="kw">in</span> tau:</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    yhat_lwr_qua <span class="op">=</span> lwr(xtrain,ytrain,xtest, Quartic,t)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    mse_lwr_qua.append(mse(ytest, yhat_lwr_qua))</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    te_tau_qua.append(t)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>  Q <span class="op">=</span> np.column_stack([xtest,yhat_lwr_qua])</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>  Q <span class="op">=</span> Q[np.argsort(Q[:,<span class="dv">0</span>])]</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>idx_min_lwr <span class="op">=</span> np.argmin(mse_lwr_qua)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Model plot</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest, ytest, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>, alpha<span class="op">=</span><span class="fl">.5</span>, edgecolors<span class="op">=</span><span class="st">&#39;k&#39;</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>plt.plot(Q[:,<span class="dv">0</span>], Q[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;Loess&#39;</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Loess with Quartic Kernel&#39;</span>)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Optimal Tau in range tested: &#39;</span>, te_tau_qua[idx_min_lwr])</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The MSE for the Locally Weighted Regression is: &#39;</span>, mse_lwr_qua[idx_min_lwr])</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_5d7290777be142f58f8e217fea7bd054/7b2e1005f8f1d70ff30e2e2712c0e807c98900f2.png" width="614" height="440" /></p>
</div>
<div class="output stream stdout">
<pre><code>Optimal Tau in range tested:  0.09999999999999999
The MSE for the Locally Weighted Regression is:  15.684994438470044
</code></pre>
</div>
</div>
<section id="comparison-between-the-locally-weighted-regression-and-the-random-forest-regression" class="cell markdown" id="kjC3JIlNQExE">
<h2>Comparison between the Locally Weighted Regression and the Random Forest Regression</h2>
<p>Both the locally weighted regression and the random forest regression perform marginally better than the ordinary least squares linear regression which had a RMSE of 6.65, which is expected since the relationship between the two variables is nonlinear. However, between the two nonparametric models, loess performed much better than the random forest with a RMSE of 3.95, while the random forest had a RMSE of 5.96. Between each of the three kernels I tested, the tricubic performed the best, however the differences in the MSE were <span class="math inline">±</span> 0.06, leaving the differences in the RMSE essentially negligible; all three are equally effective.</p>
</section>
<div class="cell code" id="nfQOBObZavQw">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
